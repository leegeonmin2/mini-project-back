# pip install deepface mediapipe opencv-python pandas tf-keras

from deepface import DeepFace
import cv2
import mediapipe as mp
import pandas as pd

# ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
image_files = {
    "images2": "images2.jpg",
    "images3": "images3.jpg",
    "images4": "images4.jpg",
    "images5": "images5.jpg",
    "smile1": "smile1.jpg",
    "smile2": "smile2.jpg",
    "smile3": "smile3.jpg",
    "smile4": "smile4.jpg",
    "neutral1": "neutral1.jpg",
    "neutral2": "neutral2.jpg",
    "neutral3": "neutral3.jpg",
}

dict_emotion_kor = {
    "angry": "í™”ë‚¨", "disgust": "í˜ì˜¤", "fear": "ë‘ë ¤ì›€",
    "happy": "í–‰ë³µ", "sad": "ìŠ¬í””", "surprise": "ë†€ëŒ", "neutral": "ë¬´í‘œì •"
}

mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)

results = []

for name, path in image_files.items():
    result = DeepFace.analyze(img_path=path, actions=['emotion'], detector_backend='mtcnn')
    dominant_emotion = result[0]["dominant_emotion"]

    image = cv2.imread(path)
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    mediapipe_result = face_mesh.process(rgb)

    # ì´ˆê¸°ê°’
    mouth_width = None
    mouth_open_ratio = None
    slope = None
    cheek_diff = None
    lip_asymmetry = None
    eyebrow_hidden = "íŒë‹¨ë¶ˆê°€"
    ear_hidden = "íŒë‹¨ë¶ˆê°€"
    gaze_result = "íŒë‹¨ë¶ˆê°€"
    face_straight = "íŒë‹¨ë¶ˆê°€"
    judgment = "íŒë‹¨ ë¶ˆê°€"

    if mediapipe_result.multi_face_landmarks:
        landmarks = mediapipe_result.multi_face_landmarks[0]
        h, w, _ = image.shape

        def get_xy(idx):
            lm = landmarks.landmark[idx]
            return lm.x * w, lm.y * h

        def get_x(idx):
            return landmarks.landmark[idx].x * w

        def get_y(idx):
            return landmarks.landmark[idx].y * h

        # ì… ê´€ë ¨ ì¢Œí‘œ
        x1, y1 = get_xy(61)
        x2, y2 = get_xy(291)
        xtop, ytop = get_xy(13)
        xbot, ybot = get_xy(14)

        # ê´‘ëŒ€
        _, cheek_left_y = get_xy(234)
        _, cheek_right_y = get_xy(454)
        cheek_diff = abs(cheek_left_y - cheek_right_y)

        # ì¤‘ì‹¬
        xnose, _ = get_xy(2)
        lip_center_x = (x1 + x2) / 2
        center_offset = abs(xnose - lip_center_x)

        # ì… ê³„ì‚°
        mouth_width = abs(x2 - x1)
        mouth_open = abs(ybot - ytop)
        mouth_open_ratio = mouth_open / mouth_width if mouth_width else 0
        slope = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else 0
        lip_asymmetry = abs(y1 - y2)

        # âœ… ëˆˆì¹ ê°€ë¦¼ ì¶”ì •
        LEFT_EYEBROW = [65, 66, 67, 68, 69]
        LEFT_EYE = 159
        eyebrow_diffs = [abs(get_y(e) - get_y(LEFT_EYE)) for e in LEFT_EYEBROW]
        avg_eyebrow_diff = sum(eyebrow_diffs) / len(eyebrow_diffs)
        eyebrow_hidden = "â­• ë³´ì„" if avg_eyebrow_diff >= 3.5 else "âŒ ê°€ë¦¼ ì˜ì‹¬"

        # âœ… ê·€ ë…¸ì¶œ ì¶”ì •
        face_width = abs(get_x(454) - get_x(234))
        ear_hidden = "â­• ë³´ì„" if face_width >= (w * 0.35) else "âŒ ê°€ë¦¼ ì˜ì‹¬"

        # âœ… ì‹œì„  ì •ë©´ ì¶”ì •
        def estimate_gaze(outer, inner, center_idx):
            outer_x = get_x(outer)
            inner_x = get_x(inner)
            center_x = get_x(center_idx)
            eye_width = abs(outer_x - inner_x)
            rel = abs(center_x - (outer_x + inner_x) / 2)
            return rel / eye_width if eye_width else 1.0

        gaze_left = estimate_gaze(33, 133, 468)
        gaze_right = estimate_gaze(362, 263, 473)
        gaze_result = "â­• ì •ë©´ ì‘ì‹œ" if gaze_left < 0.25 and gaze_right < 0.25 else "âŒ ì‹œì„  ì´íƒˆ"

        # âœ… ì–¼êµ´ ì •ë©´ ì—¬ë¶€ (ì½” ì¢Œí‘œê°€ ì–¼êµ´ ì¤‘ì•™ì¸ì§€)
        x_left_face = get_x(127)
        x_right_face = get_x(356)
        face_center_x = (x_left_face + x_right_face) / 2
        nose_offset = abs(xnose - face_center_x)
        face_straight = "â­• ì •ë©´" if nose_offset < (w * 0.03) else "âŒ ì¸¡ë©´"

        # âœ… ìµœì¢… íŒë‹¨
        if (
            (dominant_emotion in ["neutral", "happy"]) and
            (mouth_open_ratio < 0.12) and
            (mouth_width < 60) and
            (slope <= 0.05) and
            (lip_asymmetry < 4.0) and
            (cheek_diff < 6.0) and
            (center_offset < 10.0)
        ):
            judgment = "â­• ì í•©"
        else:
            judgment = "âŒ ë¶€ì í•©"

    results.append({
        "ì´ë¯¸ì§€": name,
        "ê°ì •": dict_emotion_kor.get(dominant_emotion, dominant_emotion),
        "ì…ê¼¬ë¦¬ê¸°ìš¸ê¸°": round(slope, 4) if slope else "N/A",
        "ì…ê¼¬ë¦¬ê±°ë¦¬(px)": round(mouth_width, 2) if mouth_width else "N/A",
        "ì…ë²Œì–´ì§ë¹„ìœ¨": round(mouth_open_ratio, 2) if mouth_open_ratio else "N/A",
        "ì…ê¼¬ë¦¬ë¹„ëŒ€ì¹­": round(lip_asymmetry, 2) if lip_asymmetry else "N/A",
        "ê´‘ëŒ€ë¹„ëŒ€ì¹­": round(cheek_diff, 2) if cheek_diff else "N/A",
        "ì…ì¤‘ì•™ì˜¤í”„ì…‹": round(center_offset, 2) if center_offset else "N/A",
        "ëˆˆì¹ê°€ë¦¼": eyebrow_hidden,
        "ê·€ë…¸ì¶œ": ear_hidden,
        "ì‹œì„ ì •ë©´": gaze_result,
        "ì–¼êµ´ì •ë©´": face_straight,
        "ìµœì¢… íŒë‹¨": judgment
    })

# ê²°ê³¼ ì¶œë ¥
df = pd.DataFrame(results)
print("\nğŸ“Š ìµœì¢… íŒë‹¨ ê²°ê³¼:")
print(df)
