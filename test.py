# pip install deepface mediapipe opencv-python pandas

from deepface import DeepFace
import cv2
import mediapipe as mp
import pandas as pd

# ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
image_files = {
    "images2": "images2.jpg",
    "images3": "images3.jpg",
    "images4": "images4.jpg",
    "images5": "images5.jpg",
    "smile1": "smile1.jpg",
    "smile2": "smile2.jpg",
    "smile3": "smile3.jpg",
    "smile4": "smile4.jpg",
    "neutral1": "neutral1.jpg",
    "neutral2": "neutral2.jpg",
    "neutral3": "neutral3.jpg",
}

dict_emotion_kor = {
    "angry": "í™”ë‚¨", "disgust": "í˜ì˜¤", "fear": "ë‘ë ¤ì›€",
    "happy": "í–‰ë³µ", "sad": "ìŠ¬í””", "surprise": "ë†€ëŒ", "neutral": "ë¬´í‘œì •"
}

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)

results = []

for name, path in image_files.items():
    result = DeepFace.analyze(img_path=path, actions=['emotion'], detector_backend='mtcnn')
    dominant_emotion = result[0]["dominant_emotion"]

    image = cv2.imread(path)
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    mediapipe_result = face_mesh.process(rgb)

    mouth_width = None
    mouth_open_ratio = None
    slope = None
    cheek_diff = None
    lip_asymmetry = None
    judgment = "íŒë‹¨ ë¶ˆê°€"

    if mediapipe_result.multi_face_landmarks:
        landmarks = mediapipe_result.multi_face_landmarks[0]
        h, w, _ = image.shape

        def get_xy(idx):
            lm = landmarks.landmark[idx]
            return lm.x * w, lm.y * h

        # ì… ì¢Œí‘œ
        x1, y1 = get_xy(61)   # ì™¼ìª½ ì…ê¼¬ë¦¬
        x2, y2 = get_xy(291)  # ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬
        xtop, ytop = get_xy(13)  # ì… ìœ„
        xbot, ybot = get_xy(14)  # ì… ì•„ë˜

        # ê´‘ëŒ€ ì¢Œí‘œ
        _, cheek_left_y = get_xy(234)
        _, cheek_right_y = get_xy(454)
        cheek_diff = abs(cheek_left_y - cheek_right_y)

        # ì½” ì¤‘ì‹¬
        xnose, _ = get_xy(2)
        lip_center_x = (x1 + x2) / 2
        center_offset = abs(xnose - lip_center_x)

        # ì… ë¹„ëŒ€ì¹­
        lip_asymmetry = abs(y1 - y2)

        # ì… ê´€ë ¨ ê³„ì‚°
        mouth_width = abs(x2 - x1)
        mouth_open = abs(ybot - ytop)
        mouth_open_ratio = mouth_open / mouth_width if mouth_width else 0
        slope = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else 0

        # âœ… ìµœì¢… ì í•© íŒë‹¨ ê¸°ì¤€
        if (
            (dominant_emotion in ["neutral", "happy"]) and
            (mouth_open_ratio < 0.12) and
            (mouth_width < 60) and
            (slope <= 0.05) and
            (lip_asymmetry < 4.0) and       # ì…ê¼¬ë¦¬ ì¢Œìš° ë†’ì´ì°¨
            (cheek_diff < 6.0) and          # ê´‘ëŒ€ ë†’ì´ ë¹„ëŒ€ì¹­ í—ˆìš©
            (center_offset < 10.0)          # ì… ì¤‘ì•™ê³¼ ì½” ìˆ˜ì§ì„ ì˜ ì°¨
        ):
            judgment = "â­• ì í•©"
        else:
            judgment = "âŒ ë¶€ì í•©"

    results.append({
        "ì´ë¯¸ì§€": name,
        "ê°ì •": dict_emotion_kor.get(dominant_emotion, dominant_emotion),
        "ì…ê¼¬ë¦¬ê¸°ìš¸ê¸°": round(slope, 4) if slope else "N/A",
        "ì…ê¼¬ë¦¬ê±°ë¦¬(px)": round(mouth_width, 2) if mouth_width else "N/A",
        "ì…ë²Œì–´ì§ë¹„ìœ¨": round(mouth_open_ratio, 2) if mouth_open_ratio else "N/A",
        "ì…ê¼¬ë¦¬ë¹„ëŒ€ì¹­": round(lip_asymmetry, 2) if lip_asymmetry else "N/A",
        "ê´‘ëŒ€ë¹„ëŒ€ì¹­": round(cheek_diff, 2) if cheek_diff else "N/A",
        "ì…ì¤‘ì•™ì˜¤í”„ì…‹": round(center_offset, 2) if center_offset else "N/A",
        "ìµœì¢… íŒë‹¨": judgment
    })

# ê²°ê³¼ ì¶œë ¥
import pandas as pd
df = pd.DataFrame(results)
print("\nğŸ“Š ìµœì¢… íŒë‹¨ ê²°ê³¼:")
print(df)
